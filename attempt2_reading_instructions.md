# AI Policy Course Reading Audit – Attempt 2 (Streamlined & Thematic)

This second attempt trims the curriculum to focus on thematic coherence and current relevance. It favours concise, policy‑oriented sources and encourages comparative analysis across jurisdictions. Each entry includes a summary, a guided reading plan, and one alternative suggestion where appropriate.

## 1. Reducing the Risks of AI for Military Decision Advantage (CSET, 2022)

**Summary:**  
Assesses the risks associated with deploying AI systems in military command and control, highlighting accident risks, escalation dynamics, and potential loss of human oversight. Recommends governance measures such as human‑in‑the‑loop requirements and confidence‑building between nations.

**Guided reading:**
- **Deep read:** Executive summary and recommendations to understand core concerns and proposed controls.  
- **Skim:** Technical scenario modelling unless you have a defence background.  
- **Compare:** Think about how these recommendations differ from civilian high‑risk AI regulations (e.g. EU AI Act).  

**Alternative:** For a more sceptical view, see RAND’s 2023 report on AI command resilience (if accessible).

## 2. Is Power‑Seeking AI an Existential Threat? (arXiv:2206.13353) – summary article

**Summary:**  
This position paper argues that sufficiently advanced AI systems may pursue goals that lead them to seek power and resources. It examines agentic planning, instrumental convergence, and strategic deception, responding to critics who view such scenarios as science fiction.

**Guided reading:**
- **Deep read:** Sections on instrumental convergence and deceptive alignment.  
- **Skim:** Philosophical background if you’re familiar with Bostrom’s work.  
- **Discuss:** Are power‑seeking behaviours inevitable in advanced AI, or can careful objective design preclude them?

**Alternative:** Watch the companion talk on YouTube for visual explanations and Q &A.

## 3. How Persuasive is AI‑Generated Propaganda? (CSET, 2023)

Same as in Attempt 1, but emphasise comparison between treatment groups. Focus on the policy implications rather than methodology.

## 4. Weapons of the Weak: Russia and AI‑Driven Asymmetric Warfare (Brookings, 2023)

**Summary:**  
Analyses how a relatively resource‑constrained actor (Russia) utilises AI for disinformation, cyber sabotage, and autonomous systems to offset conventional military disadvantages.

**Guided reading:**
- **Deep read:** Introduction and case studies; identify three AI tools used asymmetrically.  
- **Skim:** Historical background on asymmetric warfare.  
- **Reflect:** How might smaller states or non‑state actors employ similar tactics? What international norms could deter such misuse?

**Alternative:** Pair with CSET’s “State of Cyberwarfare 2024” for a private‑sector lens on similar threats.

## 5. History’s Message About Regulating AI (Brookings, 2023)

**Summary:**  
Draws parallels between past technological revolutions (aviation, nuclear, biotechnology) and AI, arguing that early under‑regulation often leads to crises and delayed corrective policies.

**Guided reading:**
- **Deep read:** Historical cases and lessons learned; consider which analogies are most apt.  
- **Skim:** U.S. legislative detail unless your capstone focuses on American law.  
- **Question:** Do historical patterns suggest a preferred balance between innovation and precaution? Where does AI fit on this continuum?

**Alternative:** If you need a non‑U.S. perspective, read India’s 2024 commentary on AI regulation (Carnegie Endowment).

## 6. EU AI Act – Article 57: Regulatory Sandboxes

As in Attempt 1, but emphasise comparative analysis.  

**Guided reading:**
- **Deep read:** Obligations and supervision mechanisms.  
- **Compare:** Contrast with sandbox programmes in Singapore and the U.K. (research one example).  

## 7. Computing Power and the Governance of AI (GovAI, 2022)

Same as in Attempt 1, but link explicitly to geopolitical competition. Ask whether compute controls could exacerbate techno‑nationalism.

## 8. Freedom of Speech and AI Output (Journal of Free Speech Law, 2023)

Same as in Attempt 1, but incorporate comparative law examples (EU e‑Commerce Directive, Canada’s Online Harms Act). Identify where consensus exists and where legal cultures diverge.

## 9. Copyright Policy Options for Generative AI (CEPR VoxEU, 2023)

Same as in Attempt 1, but task students with drafting a one‑paragraph policy recommendation for their jurisdiction.

## 10. The Windfall Clause: Distributing the Benefits of AI (FHI Oxford, 2017)

Use this as a capstone thinking exercise. Discuss the ethical rationale for redistributive clauses and debate implementation challenges.

---

This streamlined attempt reduces cognitive load by focusing on thematic threads (military risk, disinformation, regulatory history, sandboxing, compute, free speech, and IP). It encourages comparisons across jurisdictions and invites students to propose their own policy mechanisms.
